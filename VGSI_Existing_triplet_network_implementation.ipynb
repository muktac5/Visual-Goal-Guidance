{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GlYqaiPRaEU6"
      },
      "outputs": [],
      "source": [
        "project_path = \"drive/My Drive/VGSI\" # use the shared folder https://drive.google.com/drive/u/1/folders/1hjjcNSUSqv8AbA7R-5lIKmui-ySCEWJw\n",
        "import os\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from keras.layers import Dense, Concatenate, Input, Dropout, Bidirectional, LSTM, Dropout\n",
        "from keras.models import Sequential, Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.regularizers import l2\n",
        "from keras import backend as K\n",
        "from tensorflow.keras.layers import Layer, InputSpec\n",
        "from tensorflow.keras.layers import Lambda\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from keras.models import load_model\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "O6hc2nGvqGUF",
        "outputId": "00fbfacd-11a9-4ac0-a658-43a127458294"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotImplementedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-c57591be7355>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mFOLDERNAME\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'VGSI'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFOLDERNAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    119\u001b[0m   \u001b[0;34m\"\"\"Internal helper to mount Google Drive.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/var/colab/mp'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' is unsupported in this environment.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;34m' '\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmountpoint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotImplementedError\u001b[0m: google.colab.drive is unsupported in this environment."
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "FOLDERNAME='VGSI'\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))\n",
        "%cd /content/drive/My\\ Drive/$FOLDERNAME/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EGiNZCN-aNkj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "outputId": "bd373c15-6f57-4969-ef8d-da2c8485b372"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-9ce88f3e6853>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msample_multi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"samples/wikihow/random_sampling/train_goal_random.p\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtest_sample_multi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"samples/wikihow/random_sampling/test_goal_random.p\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_sample_multi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_sample_multi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_sample_multi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m8000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'samples/wikihow/random_sampling/train_goal_random.p'"
          ]
        }
      ],
      "source": [
        "# Samples\n",
        "sample_multi = pickle.load(open(\"samples/wikihow/random_sampling/train_goal_random.p\", \"rb\"))\n",
        "test_sample_multi = pickle.load(open(\"samples/wikihow/random_sampling/test_goal_random.p\", \"rb\"))\n",
        "print(len(test_sample_multi))\n",
        "test_sample_multi=test_sample_multi[:8000]\n",
        "print(len(test_sample_multi))\n",
        "train_sample_multi = sample_multi[:-1000]\n",
        "val_sample_multi = sample_multi[-1000:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "haqlFT--a9hJ",
        "outputId": "20522bdd-a9dd-4fb5-9a14-e6edab1509d0"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-ddc7fa5bbd7a>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mencoded_goals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"features/wikihow/encoded_goals.p\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"goal loaded!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mencoded_images_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m\"features/wikihow/encoded_images_1.p\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"image loaded!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'features/wikihow/encoded_goals.p'"
          ]
        }
      ],
      "source": [
        "# Features\n",
        "encoded_goals = pickle.load(open(\"features/wikihow/encoded_goals.p\", \"rb\" ))\n",
        "print(\"goal loaded!\")\n",
        "encoded_images_1 = pickle.load(open( \"features/wikihow/encoded_images_1.p\", \"rb\" ))\n",
        "print(\"image loaded!\")\n",
        "encoded_images_2 = pickle.load(open(\"features/wikihow/encoded_images_2.p\", \"rb\" ))\n",
        "print(\"image2 loaded!\")\n",
        "def Merge(dict1, dict2):\n",
        "    res = {**dict1, **dict2}\n",
        "    return res\n",
        "encoded_images = Merge(encoded_images_1, encoded_images_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model training"
      ],
      "metadata": {
        "id": "nSX7GBk7HuwG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WG_VK2IChS45"
      },
      "outputs": [],
      "source": [
        "def build_text_network(input_shape, embedding_size):\n",
        "    network = Sequential()\n",
        "    network.add(Dense(1024, input_shape=input_shape, activation='relu',\n",
        "                   kernel_regularizer=l2(1e-1),\n",
        "                   kernel_initializer='he_uniform'))\n",
        "    network.add(Dropout(0.5))\n",
        "    network.add(Dense(embedding_size, activation=None,\n",
        "                   kernel_regularizer=l2(1e-2),\n",
        "                   kernel_initializer='he_uniform'))\n",
        "\n",
        "    #Force the encoding to live on the d-dimentional hypershpere\n",
        "    network.add(Lambda(lambda x: K.l2_normalize(x,axis=-1)))\n",
        "\n",
        "    return network\n",
        "\n",
        "def build_img_network(input_shape, embedding_size):\n",
        "    network = Sequential()\n",
        "    network.add(Dense(1024, input_shape=input_shape, activation='relu',\n",
        "                   kernel_regularizer=l2(1e-1),\n",
        "                   kernel_initializer='he_uniform'))\n",
        "    network.add(Dropout(0.5))\n",
        "    network.add(Dense(embedding_size, activation=None,\n",
        "                   kernel_regularizer=l2(1e-2),\n",
        "                   kernel_initializer='he_uniform'))\n",
        "\n",
        "    #Force the encoding to live on the d-dimentional hypershpere\n",
        "    network.add(Lambda(lambda x: K.l2_normalize(x,axis=-1)))\n",
        "\n",
        "    return network\n",
        "\n",
        "@keras.saving.register_keras_serializable()\n",
        "class TripletLossLayer(Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(TripletLossLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def triplet_loss(self, inputs):\n",
        "        flag=False\n",
        "        anchor, positive, negative = inputs\n",
        "        p_dist = K.sum(K.square(anchor-positive), axis=-1)\n",
        "        n_dist = K.sum(K.square(anchor-negative), axis=-1)\n",
        "        #print(p_dist.numpy(),n_dist.numpy())\n",
        "        if p_dist < n_dist - 0.35:\n",
        "            flag=True\n",
        "        return flag,K.sum(K.maximum(p_dist - n_dist + 0.35, 0), axis=0)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        loss = self.triplet_loss(inputs)\n",
        "        self.add_loss(loss)\n",
        "        return loss\n",
        "\n",
        "text_network = build_text_network((768,), 1024)\n",
        "img_network = build_img_network((2048,), 1024)\n",
        "anchor_input = Input(768, name=\"anchor_input\")\n",
        "positive_input = Input(2048, name=\"positive_input\")\n",
        "negative_input = Input(2048, name=\"negative_input\")\n",
        "encoded_a = text_network(anchor_input)\n",
        "encoded_p = img_network(positive_input)\n",
        "encoded_n = img_network(negative_input)\n",
        "loss_layer = TripletLossLayer(name='triplet_loss_layer')([encoded_a,encoded_p,encoded_n])\n",
        "network_train = Model(inputs=[anchor_input,positive_input,negative_input],outputs=loss_layer)\n",
        "optimizer = Adam(lr = 0.0001)\n",
        "network_train.compile(loss=None,optimizer=optimizer)\n",
        "network_train.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2pMfu6rniYW5"
      },
      "outputs": [],
      "source": [
        "train_sample_tri = []\n",
        "for sample in tqdm(train_sample_multi):\n",
        "  a = sample[0]\n",
        "  p = sample[1][sample[-1]]\n",
        "  for i in range(4):\n",
        "    if i != sample[-1]:\n",
        "      n = sample[1][i]\n",
        "      train_sample_tri.append([a, p, n])\n",
        "\n",
        "val_sample_tri = []\n",
        "for sample in tqdm(val_sample_multi):\n",
        "  a = sample[0]\n",
        "  p = sample[1][sample[-1]]\n",
        "  for i in range(4):\n",
        "    if i != sample[-1]:\n",
        "      n = sample[1][i]\n",
        "      val_sample_tri.append([a, p, n])\n",
        "\n",
        "X_val_a = []\n",
        "X_val_p = []\n",
        "X_val_n = []\n",
        "y_val = []\n",
        "for sample in val_sample_tri:\n",
        "  X_val_a.append(encoded_goals[sample[0]].squeeze())\n",
        "  X_val_p.append(encoded_images[sample[1]].squeeze())\n",
        "  X_val_n.append(encoded_images[sample[2]].squeeze())\n",
        "  y_val.append(1)\n",
        "X_val_a = np.array(X_val_a)\n",
        "X_val_p = np.array(X_val_p)\n",
        "X_val_n = np.array(X_val_n)\n",
        "y_val = np.array(y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-DQkA5himol"
      },
      "outputs": [],
      "source": [
        "def data_loader(train_sample, batch_size):\n",
        "  count = 0\n",
        "  X_train_a_batch = []\n",
        "  X_train_p_batch = []\n",
        "  X_train_n_batch = []\n",
        "  y_train_batch = []\n",
        "  while True:\n",
        "    for sample in train_sample:\n",
        "      X_train_a_batch.append(encoded_goals[sample[0]].squeeze())\n",
        "      X_train_p_batch.append(encoded_images[sample[1]].squeeze())\n",
        "      X_train_n_batch.append(encoded_images[sample[2]].squeeze())\n",
        "      y_train_batch.append(1)\n",
        "      count += 1\n",
        "      if count > batch_size:\n",
        "        X_train_a_batch = np.array(X_train_a_batch)\n",
        "        X_train_p_batch = np.array(X_train_p_batch)\n",
        "        X_train_n_batch = np.array(X_train_n_batch)\n",
        "        y_train_batch = np.array(y_train_batch)\n",
        "        yield [X_train_a_batch, X_train_p_batch, X_train_n_batch], y_train_batch\n",
        "        count = 0\n",
        "        X_train_a_batch = []\n",
        "        X_train_p_batch = []\n",
        "        X_train_n_batch = []\n",
        "        y_train_batch = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fn8WtqnyiqxX"
      },
      "outputs": [],
      "source": [
        "history = network_train.fit(data_loader(train_sample_tri, 10000), validation_data=([X_val_a, X_val_p, X_val_n], y_val), steps_per_epoch=len(train_sample_tri)/10000, epochs=20, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MyYeD6lCQ2MK"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Training and Validation Loss Curves')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HMVAW0WZ4BMi"
      },
      "outputs": [],
      "source": [
        "network_train.save(\"/content/drive/MyDrive/triplet_model.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model load & evaluation\n"
      ],
      "metadata": {
        "id": "du_W5U6kHysv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model = load_model(\"/content/drive/MyDrive/triplet_model.h5\", custom_objects={'TripletLossLayer': TripletLossLayer})"
      ],
      "metadata": {
        "id": "skLu9AKO1YXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LwDoVLT14Dlh"
      },
      "outputs": [],
      "source": [
        "test_sample_tri = []\n",
        "for sample in tqdm(test_sample_multi):\n",
        "  a = sample[0]\n",
        "  p = sample[1][sample[-1]]\n",
        "  for i in range(4):\n",
        "    if i != sample[-1]:\n",
        "      n = sample[1][i]\n",
        "      test_sample_tri.append([a, p, n])\n",
        "\n",
        "X_test_a_batch,X_test_p_batch,X_test_n_batch=[],[],[]\n",
        "for sample in test_sample_tri:\n",
        "      X_test_a_batch.append(encoded_goals[sample[0]].squeeze())\n",
        "      X_test_p_batch.append(encoded_images[sample[1]].squeeze())\n",
        "      X_test_n_batch.append(encoded_images[sample[2]].squeeze())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct_preds=0\n",
        "for text_anchor, image_positive, image_negative in zip(X_test_a_batch,X_test_p_batch,X_test_n_batch):\n",
        "  flag,dist=network_train.predict([np.array(text_anchor).reshape(1,-1), np.array(image_positive).reshape(1,-1), np.array(image_negative).reshape(1,-1)])\n",
        "  if flag==True:\n",
        "    correct_preds=correct_preds+1\n",
        "    print(correct_preds)"
      ],
      "metadata": {
        "id": "pT0JS7BQK0on"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_samples=len(test_sample_tri)"
      ],
      "metadata": {
        "id": "HJ5k1drG5WVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = correct_preds / total_samples"
      ],
      "metadata": {
        "id": "8gb9Mu1c5M1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kr6JRXuv4Gt3"
      },
      "outputs": [],
      "source": [
        "p1=loaded_model.predict([np.array(encoded_test_anchor).reshape(1,-1), np.array(image_positive).reshape(1,-1), np.array(encoded_test_n).reshape(1,-1)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FkihxvQJ4McE"
      },
      "outputs": [],
      "source": [
        "test_loss = network_train.evaluate([X_test_a_batch, X_test_p_batch, X_test_n_batch])\n",
        "print(f'Test Loss: {test_loss}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gy1LpVY24PLd"
      },
      "outputs": [],
      "source": [
        "X_test_a_batch"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zR93KX2ylpec"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}